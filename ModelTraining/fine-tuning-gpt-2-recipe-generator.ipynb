{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13575670,"sourceType":"datasetVersion","datasetId":8624248}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ✅ Environment setup\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# ✅ Install dependencies\n!pip install transformers datasets evaluate accelerate --quiet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:16:23.449395Z","iopub.execute_input":"2025-11-01T09:16:23.449639Z","iopub.status.idle":"2025-11-01T09:17:59.953647Z","shell.execute_reply.started":"2025-11-01T09:16:23.449621Z","shell.execute_reply":"2025-11-01T09:17:59.952790Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    DataCollatorForLanguageModeling,\n    Trainer,\n    TrainingArguments,\n)\nimport torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:17:59.955018Z","iopub.execute_input":"2025-11-01T09:17:59.955318Z","iopub.status.idle":"2025-11-01T09:18:38.516534Z","shell.execute_reply.started":"2025-11-01T09:17:59.955294Z","shell.execute_reply":"2025-11-01T09:18:38.515950Z"}},"outputs":[{"name":"stderr","text":"2025-11-01 09:18:18.108293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761988698.498005      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761988698.608265      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ✅ Load the dataset (first 100K rows)\nimport pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/task1-ibi/data_100k.csv\")\n\n# ✅ Basic inspection\nprint(\"✅ Dataset loaded successfully!\")\nprint(\"Shape:\", df.shape)\ndisplay(df.head())\n\n# ✅ Check for null values\nprint(\"\\nMissing values per column:\")\nprint(df.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:18:38.517253Z","iopub.execute_input":"2025-11-01T09:18:38.517885Z","iopub.status.idle":"2025-11-01T09:18:40.745167Z","shell.execute_reply.started":"2025-11-01T09:18:38.517861Z","shell.execute_reply":"2025-11-01T09:18:40.744522Z"}},"outputs":[{"name":"stdout","text":"✅ Dataset loaded successfully!\nShape: (100000, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                         title  \\\n0                 \\t Arugula Pomegranate Salad   \n1               \\t Black Bean And Turkey Chili   \n2               \\t Finger Lickin' Tofu Nuggets   \n3  \\t Jerk Beef Stew With Carrots And Tomatoes   \n4                \\t Pomegranate Couscous Salad   \n\n                                                 NER  \\\n0  [\"baby spinach\", \"baby arugula\", \"pomegranate ...   \n1  [\"olive oil\", \"yellow onion\", \"garlic\", \"groun...   \n2  [\"extra firm\", \"almond flour\", \"nutritional ye...   \n3  [\"olive oil\", \"boneless beef chuck\", \"onion\", ...   \n4  [\"pomegranate arils\", \"whole wheat couscous\", ...   \n\n                                        Extended_NER       genre  label  \\\n0  ['alfalfa sprouts', 'baby spinach', 'baby arug...  vegetables      4   \n1  ['one', 'yellow onion', 'tomato paste', 'about...       sides      8   \n2  ['extra firm', '2', 'coconut oil', 'almond flo...      nonveg      3   \n3  ['boneless beef chuck', '2', 'Saute', 'onion',...  vegetables      4   \n4  ['whole wheat couscous', '10 minutes', 'lemon ...  vegetables      4   \n\n                                          directions  \n0  [\"Toss together spinach and arugula, then plac...  \n1  [\"Dice the onion and mince the garlic. Add the...  \n2  [\"Wrap the tofu in a clean tea towel and press...  \n3  [\"Preheat oven to 350 degrees F.\", \"Heat the o...  \n4  [\"Place couscous in a bowl with 11/2 cups of h...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>NER</th>\n      <th>Extended_NER</th>\n      <th>genre</th>\n      <th>label</th>\n      <th>directions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\t Arugula Pomegranate Salad</td>\n      <td>[\"baby spinach\", \"baby arugula\", \"pomegranate ...</td>\n      <td>['alfalfa sprouts', 'baby spinach', 'baby arug...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Toss together spinach and arugula, then plac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\t Black Bean And Turkey Chili</td>\n      <td>[\"olive oil\", \"yellow onion\", \"garlic\", \"groun...</td>\n      <td>['one', 'yellow onion', 'tomato paste', 'about...</td>\n      <td>sides</td>\n      <td>8</td>\n      <td>[\"Dice the onion and mince the garlic. Add the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\t Finger Lickin' Tofu Nuggets</td>\n      <td>[\"extra firm\", \"almond flour\", \"nutritional ye...</td>\n      <td>['extra firm', '2', 'coconut oil', 'almond flo...</td>\n      <td>nonveg</td>\n      <td>3</td>\n      <td>[\"Wrap the tofu in a clean tea towel and press...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\t Jerk Beef Stew With Carrots And Tomatoes</td>\n      <td>[\"olive oil\", \"boneless beef chuck\", \"onion\", ...</td>\n      <td>['boneless beef chuck', '2', 'Saute', 'onion',...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Preheat oven to 350 degrees F.\", \"Heat the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\t Pomegranate Couscous Salad</td>\n      <td>[\"pomegranate arils\", \"whole wheat couscous\", ...</td>\n      <td>['whole wheat couscous', '10 minutes', 'lemon ...</td>\n      <td>vegetables</td>\n      <td>4</td>\n      <td>[\"Place couscous in a bowl with 11/2 cups of h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nMissing values per column:\ntitle           0\nNER             0\nExtended_NER    0\ngenre           0\nlabel           0\ndirections      0\ndtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def make_prompt(row):\n    title = str(row['title'])\n    ingredients = str(row['Extended_NER'])  # use correct column name\n    instructions = str(row['directions'])\n    return f\"TITLE: {title}\\nINGREDIENTS: {ingredients}\\nRECIPE: {instructions}\"\n\n# Create a new text column for training\ndf['text'] = df.apply(make_prompt, axis=1)\n\n# Keep only the text column for GPT-2 training\ndf = df[['text']]\n\ndf.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:18:40.746647Z","iopub.execute_input":"2025-11-01T09:18:40.746892Z","iopub.status.idle":"2025-11-01T09:18:41.640583Z","shell.execute_reply.started":"2025-11-01T09:18:40.746874Z","shell.execute_reply":"2025-11-01T09:18:41.639937Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  TITLE: \\t Arugula Pomegranate Salad\\nINGREDIEN...\n1  TITLE: \\t Black Bean And Turkey Chili\\nINGREDI...\n2  TITLE: \\t Finger Lickin' Tofu Nuggets\\nINGREDI...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TITLE: \\t Arugula Pomegranate Salad\\nINGREDIEN...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TITLE: \\t Black Bean And Turkey Chili\\nINGREDI...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TITLE: \\t Finger Lickin' Tofu Nuggets\\nINGREDI...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)\ndataset = dataset.train_test_split(test_size=0.1, seed=42)\n\ntrain_ds = dataset['train']\ntest_ds = dataset['test']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:18:41.641292Z","iopub.execute_input":"2025-11-01T09:18:41.641561Z","iopub.status.idle":"2025-11-01T09:18:42.292170Z","shell.execute_reply.started":"2025-11-01T09:18:41.641543Z","shell.execute_reply":"2025-11-01T09:18:42.291593Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token = tokenizer.eos_token  # add padding token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:18:42.292927Z","iopub.execute_input":"2025-11-01T09:18:42.293118Z","iopub.status.idle":"2025-11-01T09:18:43.847706Z","shell.execute_reply.started":"2025-11-01T09:18:42.293103Z","shell.execute_reply":"2025-11-01T09:18:43.846918Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf9de2f6efa4cbf9fc0b8eeffa7133e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242a0a7368714e13a77366a7b4238781"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7c89733b1344a282f8b4441df88cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b7c3360e7f4b17ac514b8a9d4ca6ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9395698b224bc6a64303771d3ac210"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def tokenize_fn(examples):\n    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n\ntrain_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\ntest_ds = test_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:18:43.848588Z","iopub.execute_input":"2025-11-01T09:18:43.848873Z","iopub.status.idle":"2025-11-01T09:19:31.201357Z","shell.execute_reply.started":"2025-11-01T09:18:43.848847Z","shell.execute_reply":"2025-11-01T09:19:31.200680Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/90000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"450d4733748748f0ad4036e0f7c51a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b40591d8fc74aa7827ec0778de1b22f"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt2-recipes\",\n    # Remove evaluation_strategy if your version doesn't support it\n    # evaluation_strategy=\"epoch\",  # uncomment if you upgraded transformers\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n    gradient_accumulation_steps=4,\n    learning_rate=5e-5,\n    fp16=True,\n    logging_steps=100,\n    save_total_limit=2,\n    save_strategy=\"epoch\",\n        report_to=[]  # <- important! disables all integrations like wandb\n\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:19:31.202062Z","iopub.execute_input":"2025-11-01T09:19:31.202300Z","iopub.status.idle":"2025-11-01T09:19:31.239215Z","shell.execute_reply.started":"2025-11-01T09:19:31.202282Z","shell.execute_reply":"2025-11-01T09:19:31.238694Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainer = Trainer(\n    model=AutoModelForCausalLM.from_pretrained(\"gpt2\"),\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    processing_class=tokenizer,  # future-safe replacement\n    data_collator=DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:19:31.240007Z","iopub.execute_input":"2025-11-01T09:19:31.240491Z","iopub.status.idle":"2025-11-01T09:19:39.240581Z","shell.execute_reply.started":"2025-11-01T09:19:31.240472Z","shell.execute_reply":"2025-11-01T09:19:39.239956Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6e7e3518b1c41688934c6583461d654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f612dfcb34247df8229b5ed12cfa14b"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T09:19:39.242356Z","iopub.execute_input":"2025-11-01T09:19:39.242574Z","iopub.status.idle":"2025-11-01T10:41:55.080609Z","shell.execute_reply.started":"2025-11-01T09:19:39.242557Z","shell.execute_reply":"2025-11-01T10:41:55.079969Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5625/5625 1:22:12, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.277000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.161900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.129100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.060300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.083700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.053300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.032100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.053200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.033700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.032600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.052900</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.019200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.002700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.974900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.999600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.007700</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.007300</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.966600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.004500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.990600</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.036900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.971000</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.971700</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.974300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.970900</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.993100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.947400</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.960600</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.966100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.935900</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.956800</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.980200</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.956800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.937200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.969700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.950200</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.936000</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.942500</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.943200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.942700</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.955200</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.953100</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.965800</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.930100</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.924000</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.943200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.939900</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.950700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.944500</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.952000</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.945900</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.931600</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.951500</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.933200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.944500</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.929300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5625, training_loss=0.9868319390190973, metrics={'train_runtime': 4935.3641, 'train_samples_per_second': 18.236, 'train_steps_per_second': 1.14, 'total_flos': 1.5370801818624e+16, 'train_loss': 0.9868319390190973, 'epoch': 1.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"trainer.save_model(\"./gpt2-recipes-final\")\ntokenizer.save_pretrained(\"./gpt2-recipes-final\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T10:41:55.081252Z","iopub.execute_input":"2025-11-01T10:41:55.081462Z","iopub.status.idle":"2025-11-01T10:41:56.191828Z","shell.execute_reply.started":"2025-11-01T10:41:55.081447Z","shell.execute_reply":"2025-11-01T10:41:56.191216Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('./gpt2-recipes-final/tokenizer_config.json',\n './gpt2-recipes-final/special_tokens_map.json',\n './gpt2-recipes-final/vocab.json',\n './gpt2-recipes-final/merges.txt',\n './gpt2-recipes-final/added_tokens.json',\n './gpt2-recipes-final/tokenizer.json')"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from transformers import pipeline\n\ngenerator = pipeline(\n    \"text-generation\", \n    model=\"./gpt2-recipes-final\", \n    tokenizer=\"./gpt2-recipes-final\"\n)\n\nprompt = \"TITLE: Simple Pancakes\\nINGREDIENTS: eggs, milk, flour, sugar\\nRECIPE:\"\noutputs = generator(prompt, max_length=200, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.95)\n\nprint(outputs[0]['generated_text'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T10:48:39.088842Z","iopub.execute_input":"2025-11-01T10:48:39.089368Z","iopub.status.idle":"2025-11-01T10:48:42.090580Z","shell.execute_reply.started":"2025-11-01T10:48:39.089344Z","shell.execute_reply":"2025-11-01T10:48:42.089734Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nBoth `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"TITLE: Simple Pancakes\nINGREDIENTS: eggs, milk, flour, sugar\nRECIPE: [\"Beat eggs, milk, flour, sugar, and spices together.\", \"Stir in pancake mixture.\", \"Pour into greased baking dish.\", \"Bake at 350\\u00b0 for 1 hour.\"]\nRECIPE: [\"Preheat oven to 350\\u00b0.\", \"Melt butter in a large skillet over medium heat.\", \"Add eggs and cook over medium heat, stirring constantly until golden brown, about 1 minute.\"]\nServe with crackers or crackers cake.\", \"Serves 6.\"]\nRECIPE: [\"In a small bowl, whisk together egg yolks and oil. Add flour, salt and pepper.\", \"Mix well.\", \"Add pancake mixture, stirring to combine.\", \"Sprinkle with crackers.\", \"Top with remaining batter.\"]\nRECIPE: [\"In a large skillet over medium heat, melt butter.\", \"Add eggs, then add milk, stirring to combine.\", \"Pour into a greased baking dish.\", \"Bake at 350\\u00b0 for 1 hour.\"]\"]]\"]]\"]]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\"]\n","output_type":"stream"}],"execution_count":14}]}